{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8222fd-8e11-49eb-8772-859ae12314bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamil/Desktop/git/meteoapp-data/venv/lib/python3.11/site-packages/gribapi/__init__.py:23: UserWarning: ecCodes 2.31.0 or higher is recommended. You are running version 2.30.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from baselines.gnn.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e96222-4498-45e5-ab0b-dab20c2fcf2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 50.47665572166443 [s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "trainer = Trainer(architecture='cgcn', hidden_dim=32, lr=1e-3)\n",
    "trainer.load_model('test.pt')\n",
    "stop = time.time()\n",
    "print(f'Elapsed time: {stop-start} [s]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f632d-c83d-42b0-a329-cbf845a3e0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcdf3215-d13d-4de5-8670-f6b5e61ad345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.plot_predictions(\"train\")\n",
    "# trainer.plot_predictions(\"val\")\n",
    "# trainer.plot_predictions(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7ab0e2f-6950-4ea7-aae5-3ac46758a123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for t2m: 1.6952537633175977; MAE for t2m: 1.2963810017395128;\n",
      "RMSE for sp: 2.5099427447058607; MAE for sp: 1.888355992171436;\n",
      "RMSE for tcc: 0.2719827234256886; MAE for tcc: 0.20926302628794602;\n",
      "RMSE for u10: 1.3179325623979044; MAE for u10: 0.9835874039577532;\n",
      "RMSE for v10: 1.3030408601221635; MAE for v10: 0.969452200677228;\n",
      "RMSE for tp: 0.00025403116192478; MAE for tp: 0.00010138416397522353;\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729d171b-9058-4e1b-a72c-ebcd31ac9768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for t2m: 1.9697479380658318; MAE for t2m: 1.4618393547326245;\n",
      "RMSE for sp: 2.662431183717692; MAE for sp: 2.0038431590870958;\n",
      "RMSE for tcc: 0.28091842310133797; MAE for tcc: 0.21867236585947047;\n",
      "RMSE for u10: 1.431303235004292; MAE for u10: 1.0705641029016144;\n",
      "RMSE for v10: 1.3919697989211088; MAE for v10: 1.0321245012587077;\n",
      "RMSE for tp: 0.0002881742851786081; MAE for tp: 0.00010770761775780729;\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b0f57d-cef3-44e0-b44c-39c5e124e99b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for t2m: 1.794229245261098; MAE for t2m: 1.3804372961847688;\n",
      "RMSE for sp: 2.6630094418268966; MAE for sp: 2.0115444393495943;\n",
      "RMSE for tcc: 0.27882748054409445; MAE for tcc: 0.2158870989551258;\n",
      "RMSE for u10: 1.421792956051873; MAE for u10: 1.064024085896917;\n",
      "RMSE for v10: 1.4246480981285705; MAE for v10: 1.0543524988571005;\n",
      "RMSE for tp: 0.0002700917139003329; MAE for tp: 0.00010419612027755113;\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7a7d96-8bc8-4e01-8c9a-c4cc407b23f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [CGCN]\n",
    "\n",
    "### Full training:\n",
    "\n",
    "N = 5; hidden = 32; batch=4; s = 3:\n",
    " \n",
    "RMSE for f0: 2.2464043976548047; MAE for f0: 1.6999678436793948;\n",
    "\n",
    "RMSE for f1: 1.9364765893388307; MAE for f1: 1.408220916940946;\n",
    "\n",
    "RMSE for f2: 0.28386787466464225; MAE for f2: 0.21952327282997064;\n",
    "\n",
    "RMSE for f3: 1.411270602820433; MAE for f3: 1.0502013356032074;\n",
    "\n",
    "RMSE for f4: 1.412410520285922; MAE for f4: 1.0404767270553594;\n",
    "\n",
    "RMSE for f5: 0.0002722878701922671; MAE for f5: 0.0001054861260521275;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 64; batch=4; s = 3:\n",
    "\n",
    "RMSE for f0: 2.205407197194004; MAE for f0: 1.6519353043910658;\n",
    "\n",
    "RMSE for f1: 2.029980887836009; MAE for f1: 1.4714761668475365;\n",
    "\n",
    "RMSE for f2: 0.28731255755261337; MAE for f2: 0.22192368753909236;\n",
    "\n",
    "RMSE for f3: 1.4478491874482888; MAE for f3: 1.0733782789693203;\n",
    "\n",
    "RMSE for f4: 1.4493260989133352; MAE for f4: 1.058615083231145;\n",
    "\n",
    "RMSE for f5: 0.0002749573712955729; MAE for f5: 0.00010411299434883103;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "With bigger batch_size training is more stable (almost no overfitting) but it does not improve performance\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 10; hidden = 32; batch=32; no significant difference, much longer training; even worse performance\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 10; hidden = 32; batch=32; mlp - 3 layers for encoder and decoder each - totally failed to learn sufficient representation; loss after 100 epochs is 2x bigger\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "With gradient clip=100; h=32; b=32; n=5 -> loss plot is more smooth; no performance improvement\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "Using learning constants advised by authors of graphcast does not improve performance (it is actually worse) but training is super stable - no overfittin at all:\n",
    "clip=32; self.optimizer = torch.optim.AdamW(self.model.parameters(), betas=(0.9, 0.95), weight_decay=0.1); h=32; b=32\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 32; batch = 4; s = 7\n",
    "\n",
    "Epoch 100/100, Train Loss: 1848.7699, lr: 3.125e-05 Val Loss: 2230.6389\n",
    "735.7001855373383 [s]22666046945865614\n",
    "\n",
    "RMSE for t2m: 1.8891855143316563; MAE for t2m: 1.4600152796625336;\n",
    "\n",
    "RMSE for sp: 2.0393454691406316; MAE for sp: 1.5120049358744065;\n",
    "\n",
    "RMSE for tcc: 0.2860184447921189; MAE for tcc: 0.22666046945865614;\n",
    "\n",
    "RMSE for u10: 1.4378177755816777; MAE for u10: 1.0736904505733116;\n",
    "\n",
    "RMSE for v10: 1.4574477223923084; MAE for v10: 1.0663613129750227;\n",
    "\n",
    "RMSE for tp: 0.0002711004547077864; MAE for tp: 0.00010284140930705948;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 32; batch = 4; s = 3\n",
    "\n",
    "Epoch 99/100, Train Loss: 1955.0575, lr: 0.0005 Val Loss: 2207.3025\n",
    "\n",
    "693.315672159195 [s]\n",
    "\n",
    "RMSE for t2m: 2.3858469221825898; MAE for t2m: 1.8332994478389537;\n",
    "\n",
    "RMSE for sp: 1.9815898823743083; MAE for sp: 1.4750331930477616;\n",
    "\n",
    "RMSE for tcc: 0.28416700897460695; MAE for tcc: 0.23001444125440887;\n",
    "\n",
    "RMSE for u10: 1.4444404739897925; MAE for u10: 1.0740849332227052;\n",
    "\n",
    "RMSE for v10: 1.4384182183045433; MAE for v10: 1.05619047567965;\n",
    "\n",
    "RMSE for tp: 0.0002669724249068656; MAE for tp: 0.00010341137409668945;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 32; batch = 4; s = 5\n",
    "\n",
    "Epoch 100/100, Train Loss: 1901.1544, lr: 6.25e-05 Val Loss: 2181.1193\n",
    "\n",
    "678.085875749588 [s]\n",
    "\n",
    "RMSE for t2m: 1.8778959983044772; MAE for t2m: 1.4465936457254398;\n",
    "\n",
    "RMSE for sp: 2.190103341129505; MAE for sp: 1.6404208756272267;\n",
    "\n",
    "RMSE for tcc: 0.2848521568307657; MAE for tcc: 0.22361195825242483;\n",
    "\n",
    "RMSE for u10: 1.437490006965024; MAE for u10: 1.0706755302203412;\n",
    "\n",
    "RMSE for v10: 1.4364091328286357; MAE for v10: 1.0579831289563082;\n",
    "\n",
    "RMSE for tp: 0.0002660477946055829; MAE for tp: 0.00010596483422627151;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 32; batch = 4; s = 5; r=2\n",
    "\n",
    "Epoch 100/100, Train Loss: 1882.7291, lr: 1.5625e-05 Val Loss: 2143.8953 (*at some point 2129)\n",
    "\n",
    "887.3842961788177 [s]\n",
    "\n",
    "RMSE for t2m: 1.8323451416138599; MAE for t2m: 1.4136113810162858;\n",
    "\n",
    "RMSE for sp: 2.0521229454022802; MAE for sp: 1.527130837420577;\n",
    "\n",
    "RMSE for tcc: 0.2793271584790608; MAE for tcc: 0.21826436014217337;\n",
    "\n",
    "RMSE for u10: 1.3972067698487758; MAE for u10: 1.0433846660489516;\n",
    "\n",
    "RMSE for v10: 1.4072224335796066; MAE for v10: 1.0366618030650943;\n",
    "\n",
    "RMSE for tp: 0.00026956517312684114; MAE for tp: 0.0001043501217544922;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 32; batch = 4; s = 5; r = 2; 32x48;\n",
    "\n",
    "Epoch 100/100, Train Loss: 2461.7144, lr: 6.25e-05 Val Loss: 3011.8880\n",
    "\n",
    "1520.1190974712372 [s]\n",
    "\n",
    "RMSE for t2m: 1.7308520625058639; MAE for t2m: 1.3247728998925457;\n",
    "\n",
    "RMSE for sp: 2.3992479669737645; MAE for sp: 1.7568102339318754;\n",
    "\n",
    "RMSE for tcc: 0.2805274129657387; MAE for tcc: 0.21913696437798416;\n",
    "\n",
    "RMSE for u10: 1.4401554352858472; MAE for u10: 1.0654466357169252;\n",
    "\n",
    "RMSE for v10: 1.4595404951536077; MAE for v10: 1.0686582104736524;\n",
    "\n",
    "RMSE for tp: 0.0002717262792747912; MAE for tp: 0.00010331567566263692;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 32; batch = 4; s = 5; r = 2; 32x48 -> 25x45;\n",
    "~ 1140 s; Train Loss: 1686.4399, lr: 6.25e-05Val Loss: 2182.0108 (2 trainings)\n",
    "\n",
    "RMSE for t2m: 1.784685209006511; MAE for t2m: 1.3758342778804562;\n",
    "\n",
    "RMSE for sp: 2.7761703742751234; MAE for sp: 2.0798808012966767;\n",
    "\n",
    "RMSE for tcc: 0.278589605641175; MAE for tcc: 0.21694147138915904;\n",
    "\n",
    "RMSE for u10: 1.413366736459174; MAE for u10: 1.0589858767124307;\n",
    "\n",
    "RMSE for v10: 1.416900322369188; MAE for v10: 1.0449888444043014;\n",
    "\n",
    "RMSE for tp: 0.00027346005336134616; MAE for tp: 0.00010490509133304818;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
