{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8222fd-8e11-49eb-8772-859ae12314bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from baselines.gnn.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e96222-4498-45e5-ab0b-dab20c2fcf2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "trainer = Trainer(architecture='trans', hidden_dim=32, lr=1e-3)\n",
    "# trainer.load_model('test.pt')\n",
    "stop = time.time()\n",
    "print(f'Elapsed time: {stop-start} [s]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f6d29-9b58-4831-9694-b6518934a68b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next(iter(trainer.train_loader)).x.size(0) / 4 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb8110-87d3-49b3-9042-260db191ee24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf3215-d13d-4de5-8670-f6b5e61ad345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.plot_predictions(\"train\")\n",
    "# trainer.plot_predictions(\"val\")\n",
    "# trainer.plot_predictions(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab0e2f-6950-4ea7-aae5-3ac46758a123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.evaluate(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d171b-9058-4e1b-a72c-ebcd31ac9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0f57d-cef3-44e0-b44c-39c5e124e99b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.evaluate(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482fda92-4602-43ce-b9fe-e3ee6ad5b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2020-2022.grib\n",
    "\n",
    "# Transformer: Epoch 50/50, Train Loss: 1631.7028, lr: 0.000125 Val Loss: 1995.9098  *10 epoch < 2.1k                    627.07288813591 [s]; 577.6894102096558 [s] - no spatial mapping Val Loss: 2773.0315\n",
    "\n",
    "# GAT:         Epoch 50/50, Train Loss: 1912.3626, lr: 6.25e-05 Val Loss: 2068.4888  *rmse sp ~ 6                        710.3302898406982 [s]; \n",
    "\n",
    "# GEN:         Epoch 50/50, Train Loss: 1738.9288, lr: 0.000125 Val Loss: 2400.2730  *rmse sp ~ 6                        632.7618696689606 [s]\n",
    "#              Epoch 50/50, Train Loss: 1926.7893, lr: 3.125e-05Val Loss: 2358.8036                                      250.7063798904419 [s] with num_layers!!!\n",
    "\n",
    "# CGCN:        Epoch 50/50, Train Loss: 1973.3904, lr: 0.001    Val Loss: 2126.4853                                      580.7204239368439 [s]\n",
    "\n",
    "# PDN:         Epoch 50/50, Train Loss: 1991.0188, lr: 0.000125 Val Loss: 2150.5120 *rmse sp ~ 6                         674.661036491394 [s]\n",
    "# h_chnnls*4   Epoch 50/50, Train Loss: 1984.7307, lr: 0.00025  Val Loss: 2160.6990                                      660.2813837528229 [s]\n",
    "\n",
    "\n",
    "# BEST mapping:\n",
    "\n",
    "# RMSE for t2m: 1.9502057215900213; MAE for t2m: 1.460449989283434;\n",
    "# RMSE for sp: 3.399038812459811; MAE for sp: 2.5950842092613984;\n",
    "# RMSE for tcc: 0.27409164273468917; MAE for tcc: 0.21394984584361584;\n",
    "# RMSE for u10: 1.3402054937222394; MAE for u10: 1.003815006674253;\n",
    "# RMSE for v10: 1.3046558578388197; MAE for v10: 0.9701394707445763;\n",
    "# RMSE for tp: 0.00028378795573663634; MAE for tp: 9.744955463428279e-05;\n",
    "\n",
    "# BEST no mapping:\n",
    "\n",
    "# RMSE for t2m: 1.848757972304198; MAE for t2m: 1.395213300597085;\n",
    "# RMSE for sp: 3.449658892501596; MAE for sp: 2.667022191931498;\n",
    "# RMSE for tcc: 0.27683438137853805; MAE for tcc: 0.21672284132768843;\n",
    "# RMSE for u10: 1.410872957033123; MAE for u10: 1.0491217187220006;\n",
    "# RMSE for v10: 1.3660170921185273; MAE for v10: 1.0087554784574733;\n",
    "# RMSE for tp: 0.00027853536544616465; MAE for tp: 9.733342513856305e-05;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7a7d96-8bc8-4e01-8c9a-c4cc407b23f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [CGCN]\n",
    "\n",
    "### Full training:\n",
    "\n",
    "N = 5; hidden = 32; batch=4; s = 3:\n",
    " \n",
    "RMSE for f0: 2.2464043976548047; MAE for f0: 1.6999678436793948;\n",
    "\n",
    "RMSE for f1: 1.9364765893388307; MAE for f1: 1.408220916940946;\n",
    "\n",
    "RMSE for f2: 0.28386787466464225; MAE for f2: 0.21952327282997064;\n",
    "\n",
    "RMSE for f3: 1.411270602820433; MAE for f3: 1.0502013356032074;\n",
    "\n",
    "RMSE for f4: 1.412410520285922; MAE for f4: 1.0404767270553594;\n",
    "\n",
    "RMSE for f5: 0.0002722878701922671; MAE for f5: 0.0001054861260521275;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 64; batch=4; s = 3:\n",
    "\n",
    "RMSE for f0: 2.205407197194004; MAE for f0: 1.6519353043910658;\n",
    "\n",
    "RMSE for f1: 2.029980887836009; MAE for f1: 1.4714761668475365;\n",
    "\n",
    "RMSE for f2: 0.28731255755261337; MAE for f2: 0.22192368753909236;\n",
    "\n",
    "RMSE for f3: 1.4478491874482888; MAE for f3: 1.0733782789693203;\n",
    "\n",
    "RMSE for f4: 1.4493260989133352; MAE for f4: 1.058615083231145;\n",
    "\n",
    "RMSE for f5: 0.0002749573712955729; MAE for f5: 0.00010411299434883103;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "With bigger batch_size training is more stable (almost no overfitting) but it does not improve performance\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 10; hidden = 32; batch=32; no significant difference, much longer training; even worse performance\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 10; hidden = 32; batch=32; mlp - 3 layers for encoder and decoder each - totally failed to learn sufficient representation; loss after 100 epochs is 2x bigger\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "With gradient clip=100; h=32; b=32; n=5 -> loss plot is more smooth; no performance improvement\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "Using learning constants advised by authors of graphcast does not improve performance (it is actually worse) but training is super stable - no overfittin at all:\n",
    "clip=32; self.optimizer = torch.optim.AdamW(self.model.parameters(), betas=(0.9, 0.95), weight_decay=0.1); h=32; b=32\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 32; batch = 4; s = 7\n",
    "\n",
    "Epoch 100/100, Train Loss: 1848.7699, lr: 3.125e-05 Val Loss: 2230.6389\n",
    "735.7001855373383 [s]22666046945865614\n",
    "\n",
    "RMSE for t2m: 1.8891855143316563; MAE for t2m: 1.4600152796625336;\n",
    "\n",
    "RMSE for sp: 2.0393454691406316; MAE for sp: 1.5120049358744065;\n",
    "\n",
    "RMSE for tcc: 0.2860184447921189; MAE for tcc: 0.22666046945865614;\n",
    "\n",
    "RMSE for u10: 1.4378177755816777; MAE for u10: 1.0736904505733116;\n",
    "\n",
    "RMSE for v10: 1.4574477223923084; MAE for v10: 1.0663613129750227;\n",
    "\n",
    "RMSE for tp: 0.0002711004547077864; MAE for tp: 0.00010284140930705948;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 32; batch = 4; s = 3\n",
    "\n",
    "Epoch 99/100, Train Loss: 1955.0575, lr: 0.0005 Val Loss: 2207.3025\n",
    "\n",
    "693.315672159195 [s]\n",
    "\n",
    "RMSE for t2m: 2.3858469221825898; MAE for t2m: 1.8332994478389537;\n",
    "\n",
    "RMSE for sp: 1.9815898823743083; MAE for sp: 1.4750331930477616;\n",
    "\n",
    "RMSE for tcc: 0.28416700897460695; MAE for tcc: 0.23001444125440887;\n",
    "\n",
    "RMSE for u10: 1.4444404739897925; MAE for u10: 1.0740849332227052;\n",
    "\n",
    "RMSE for v10: 1.4384182183045433; MAE for v10: 1.05619047567965;\n",
    "\n",
    "RMSE for tp: 0.0002669724249068656; MAE for tp: 0.00010341137409668945;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 32; batch = 4; s = 5\n",
    "\n",
    "Epoch 100/100, Train Loss: 1901.1544, lr: 6.25e-05 Val Loss: 2181.1193\n",
    "\n",
    "678.085875749588 [s]\n",
    "\n",
    "RMSE for t2m: 1.8778959983044772; MAE for t2m: 1.4465936457254398;\n",
    "\n",
    "RMSE for sp: 2.190103341129505; MAE for sp: 1.6404208756272267;\n",
    "\n",
    "RMSE for tcc: 0.2848521568307657; MAE for tcc: 0.22361195825242483;\n",
    "\n",
    "RMSE for u10: 1.437490006965024; MAE for u10: 1.0706755302203412;\n",
    "\n",
    "RMSE for v10: 1.4364091328286357; MAE for v10: 1.0579831289563082;\n",
    "\n",
    "RMSE for tp: 0.0002660477946055829; MAE for tp: 0.00010596483422627151;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 32; batch = 4; s = 5; r=2\n",
    "\n",
    "Epoch 100/100, Train Loss: 1882.7291, lr: 1.5625e-05 Val Loss: 2143.8953 (*at some point 2129)\n",
    "\n",
    "887.3842961788177 [s]\n",
    "\n",
    "RMSE for t2m: 1.8323451416138599; MAE for t2m: 1.4136113810162858;\n",
    "\n",
    "RMSE for sp: 2.0521229454022802; MAE for sp: 1.527130837420577;\n",
    "\n",
    "RMSE for tcc: 0.2793271584790608; MAE for tcc: 0.21826436014217337;\n",
    "\n",
    "RMSE for u10: 1.3972067698487758; MAE for u10: 1.0433846660489516;\n",
    "\n",
    "RMSE for v10: 1.4072224335796066; MAE for v10: 1.0366618030650943;\n",
    "\n",
    "RMSE for tp: 0.00026956517312684114; MAE for tp: 0.0001043501217544922;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 32; batch = 4; s = 5; r = 2; 32x48;\n",
    "\n",
    "Epoch 100/100, Train Loss: 2461.7144, lr: 6.25e-05 Val Loss: 3011.8880\n",
    "\n",
    "1520.1190974712372 [s]\n",
    "\n",
    "RMSE for t2m: 1.7308520625058639; MAE for t2m: 1.3247728998925457;\n",
    "\n",
    "RMSE for sp: 2.3992479669737645; MAE for sp: 1.7568102339318754;\n",
    "\n",
    "RMSE for tcc: 0.2805274129657387; MAE for tcc: 0.21913696437798416;\n",
    "\n",
    "RMSE for u10: 1.4401554352858472; MAE for u10: 1.0654466357169252;\n",
    "\n",
    "RMSE for v10: 1.4595404951536077; MAE for v10: 1.0686582104736524;\n",
    "\n",
    "RMSE for tp: 0.0002717262792747912; MAE for tp: 0.00010331567566263692;\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "N = 5; hidden = 32; batch = 4; s = 5; r = 2; 32x48 -> 25x45;\n",
    "~ 1140 s; Train Loss: 1686.4399, lr: 6.25e-05Val Loss: 2182.0108 (2 trainings)\n",
    "\n",
    "RMSE for t2m: 1.784685209006511; MAE for t2m: 1.3758342778804562;\n",
    "\n",
    "RMSE for sp: 2.7761703742751234; MAE for sp: 2.0798808012966767;\n",
    "\n",
    "RMSE for tcc: 0.278589605641175; MAE for tcc: 0.21694147138915904;\n",
    "\n",
    "RMSE for u10: 1.413366736459174; MAE for u10: 1.0589858767124307;\n",
    "\n",
    "RMSE for v10: 1.416900322369188; MAE for v10: 1.0449888444043014;\n",
    "\n",
    "RMSE for tp: 0.00027346005336134616; MAE for tp: 0.00010490509133304818;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
