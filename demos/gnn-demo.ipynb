{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8222fd-8e11-49eb-8772-859ae12314bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamil/Desktop/git/meteoapp-data/venv/lib/python3.11/site-packages/gribapi/__init__.py:23: UserWarning: ecCodes 2.31.0 or higher is recommended. You are running version 2.30.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.append('..')\n",
    "\n",
    "from models.gnn.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e96222-4498-45e5-ab0b-dab20c2fcf2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 59.08777976036072 [s]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "trainer = Trainer(architecture='trans', hidden_dim=32, lr=1e-3)\n",
    "stop = time.time()\n",
    "print(f'Elapsed time: {stop-start} [s]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205432ff-1117-4872-a8ad-103329bdcd18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[1536, 6, 5], edge_index=[2, 17636], edge_attr=[17636, 3], y=[1536, 6, 1], pos=[1, 1536, 6], time=[4], batch=[1536], ptr=[2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trainer.train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e84b7463-a62a-43d8-95e3-5e70415dad96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models.config import config as cfg\n",
    "cfg.FH = 1\n",
    "cfg.INPUT_SIZE = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7b13c46-7859-473d-abda-8f7b66d51aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.update_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97b274f7-e172-4e9c-b1f9-283a23a85dea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[1536, 6, 6], edge_index=[2, 17636], edge_attr=[17636, 3], y=[1536, 6, 1], pos=[1, 1536, 6], time=[4], batch=[1536], ptr=[2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trainer.train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94606484-d1cd-4955-a8ec-6868d3c8b461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = trainer.nn_proc.data_proc.spatial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a82f6d29-9b58-4831-9694-b6518934a68b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next(iter(trainer.train_loader)).x.size(0) / 4 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f8ea9c5-ecd4-4513-99b7-f8fe21379a73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4608"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next(iter(trainer.train_loader)).x.size(0) + next(iter(trainer.val_loader)).x.size(0)  + next(iter(trainer.test_loader)).x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb8110-87d3-49b3-9042-260db191ee24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train(num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e99558-6984-4b74-a60d-744a4ea71e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.plot_predictions(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcdf3215-d13d-4de5-8670-f6b5e61ad345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.plot_predictions(\"train\")\n",
    "# trainer.plot_predictions(\"val\")\n",
    "# trainer.plot_predictions(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7ab0e2f-6950-4ea7-aae5-3ac46758a123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for t2m: 1.486813050474434; MAE for t2m: 1.1151851850570522;\n",
      "RMSE for sp: 1.4465060356827117; MAE for sp: 1.0977039391367518;\n",
      "RMSE for tcc: 0.26794322644755336; MAE for tcc: 0.17747914047558075;\n",
      "RMSE for u10: 1.1444530627741039; MAE for u10: 0.8386240623944919;\n",
      "RMSE for v10: 1.1085909905675497; MAE for v10: 0.8108103474286411;\n",
      "RMSE for tp: 0.00025706294562224995; MAE for tp: 6.785745771978782e-05;\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "729d171b-9058-4e1b-a72c-ebcd31ac9768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for t2m: 1.598837305403512; MAE for t2m: 1.207806370915157;\n",
      "RMSE for sp: 1.5673467253045223; MAE for sp: 1.1845101375160045;\n",
      "RMSE for tcc: 0.2896158273654131; MAE for tcc: 0.19197069795521024;\n",
      "RMSE for u10: 1.2482659041865094; MAE for u10: 0.9257073768692872;\n",
      "RMSE for v10: 1.229148308696463; MAE for v10: 0.9054445361238508;\n",
      "RMSE for tp: 0.0003013579409649854; MAE for tp: 8.373013352743387e-05;\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b0f57d-cef3-44e0-b44c-39c5e124e99b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for t2m: 1.8655561865824044; MAE for t2m: 1.4112141290124285;\n",
      "RMSE for sp: 2.9318951819298427; MAE for sp: 2.325906363371561;\n",
      "RMSE for tcc: 0.2907433827815204; MAE for tcc: 0.19983432042826127;\n",
      "RMSE for u10: 1.41066109305344; MAE for u10: 1.0629070387708428;\n",
      "RMSE for v10: 1.3126685515729526; MAE for v10: 0.9777745120699456;\n",
      "RMSE for tp: 0.0002920171775604999; MAE for tp: 7.977836600488345e-05;\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "482fda92-4602-43ce-b9fe-e3ee6ad5b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2020-2022.grib\n",
    "\n",
    "# Transformer: Epoch 50/50, Train Loss: 1631.7028, lr: 0.000125 Val Loss: 1995.9098  *10 epoch < 2.1k                    627.07288813591 [s]; 577.6894102096558 [s] - no spatial mapping Val Loss: 2773.0315\n",
    "\n",
    "# GAT:         Epoch 50/50, Train Loss: 1912.3626, lr: 6.25e-05 Val Loss: 2068.4888  *rmse sp ~ 6                        710.3302898406982 [s]; \n",
    "\n",
    "# GEN:         Epoch 50/50, Train Loss: 1738.9288, lr: 0.000125 Val Loss: 2400.2730  *rmse sp ~ 6                        632.7618696689606 [s]\n",
    "#              Epoch 50/50, Train Loss: 1926.7893, lr: 3.125e-05Val Loss: 2358.8036                                      250.7063798904419 [s] with num_layers!!!\n",
    "\n",
    "# CGCN:        Epoch 50/50, Train Loss: 1973.3904, lr: 0.001    Val Loss: 2126.4853                                      580.7204239368439 [s]\n",
    "\n",
    "# PDN:         Epoch 50/50, Train Loss: 1991.0188, lr: 0.000125 Val Loss: 2150.5120 *rmse sp ~ 6                         674.661036491394 [s]\n",
    "# h_chnnls*4   Epoch 50/50, Train Loss: 1984.7307, lr: 0.00025  Val Loss: 2160.6990                                      660.2813837528229 [s]\n",
    "\n",
    "\n",
    "# BEST mapping:\n",
    "\n",
    "# RMSE for t2m: 1.9502057215900213; MAE for t2m: 1.460449989283434;\n",
    "# RMSE for sp: 3.399038812459811; MAE for sp: 2.5950842092613984;\n",
    "# RMSE for tcc: 0.27409164273468917; MAE for tcc: 0.21394984584361584;\n",
    "# RMSE for u10: 1.3402054937222394; MAE for u10: 1.003815006674253;\n",
    "# RMSE for v10: 1.3046558578388197; MAE for v10: 0.9701394707445763;\n",
    "# RMSE for tp: 0.00028378795573663634; MAE for tp: 9.744955463428279e-05;\n",
    "\n",
    "# BEST no mapping:\n",
    "\n",
    "# RMSE for t2m: 1.848757972304198; MAE for t2m: 1.395213300597085;\n",
    "# RMSE for sp: 3.449658892501596; MAE for sp: 2.667022191931498;\n",
    "# RMSE for tcc: 0.27683438137853805; MAE for tcc: 0.21672284132768843;\n",
    "# RMSE for u10: 1.410872957033123; MAE for u10: 1.0491217187220006;\n",
    "# RMSE for v10: 1.3660170921185273; MAE for v10: 1.0087554784574733;\n",
    "# RMSE for tp: 0.00027853536544616465; MAE for tp: 9.733342513856305e-05;\n",
    "\n",
    "# lowest we get with new features; mapping:\n",
    "# Epoch 36/50, Train Loss: 1880.5901, lr: 0.0005\n",
    "# Val Loss: 2332.4124\n",
    "# RMSE for t2m: 1.8650685428773215; MAE for t2m: 1.4327338052306162;\n",
    "# RMSE for sp: 3.125996870921546; MAE for sp: 2.394205469596666;\n",
    "# RMSE for tcc: 0.2769834191870229; MAE for tcc: 0.21654550355782148;\n",
    "# RMSE for u10: 1.3499078509381048; MAE for u10: 1.0095530567394215;\n",
    "# RMSE for v10: 1.3224928259398205; MAE for v10: 0.9903028884270412;\n",
    "# RMSE for tp: 0.00028549145677631216; MAE for tp: 0.0001046686964487334;\n",
    "\n",
    "# loqwest we get with new feature no mapping:\n",
    "# Epoch 36/50, Train Loss: 1950.8919, lr: 0.0005\n",
    "# Val Loss: 2511.0089\n",
    "# ---------\n",
    "# RMSE for t2m: 1.9533919521164234; MAE for t2m: 1.4978515430230384;\n",
    "# RMSE for sp: 2.8703930929801524; MAE for sp: 2.198967421439784;\n",
    "# RMSE for tcc: 0.27739108423280834; MAE for tcc: 0.21839308087625517;\n",
    "# RMSE for u10: 1.3687520654035368; MAE for u10: 1.0232698703248595;\n",
    "# RMSE for v10: 1.327701042680353; MAE for v10: 0.9899769595131284;\n",
    "# RMSE for tp: 0.0002961515820969641; MAE for tp: 0.00010478641882246229;\n",
    "\n",
    "# factor  0.732421875\n",
    "# Epoch 26/50, Train Loss: 2882.6302, lr: 0.001\n",
    "# Val Loss: 3317.5983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "974c5753-4ba2-4407-8fd7-69655f18449d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # [CGCN]\n",
    "\n",
    "# ### Full training:\n",
    "\n",
    "# N = 5; hidden = 32; batch=4; s = 3:\n",
    " \n",
    "# RMSE for f0: 2.2464043976548047; MAE for f0: 1.6999678436793948;\n",
    "\n",
    "# RMSE for f1: 1.9364765893388307; MAE for f1: 1.408220916940946;\n",
    "\n",
    "# RMSE for f2: 0.28386787466464225; MAE for f2: 0.21952327282997064;\n",
    "\n",
    "# RMSE for f3: 1.411270602820433; MAE for f3: 1.0502013356032074;\n",
    "\n",
    "# RMSE for f4: 1.412410520285922; MAE for f4: 1.0404767270553594;\n",
    "\n",
    "# RMSE for f5: 0.0002722878701922671; MAE for f5: 0.0001054861260521275;\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# N = 5; hidden = 64; batch=4; s = 3:\n",
    "\n",
    "# RMSE for f0: 2.205407197194004; MAE for f0: 1.6519353043910658;\n",
    "\n",
    "# RMSE for f1: 2.029980887836009; MAE for f1: 1.4714761668475365;\n",
    "\n",
    "# RMSE for f2: 0.28731255755261337; MAE for f2: 0.22192368753909236;\n",
    "\n",
    "# RMSE for f3: 1.4478491874482888; MAE for f3: 1.0733782789693203;\n",
    "\n",
    "# RMSE for f4: 1.4493260989133352; MAE for f4: 1.058615083231145;\n",
    "\n",
    "# RMSE for f5: 0.0002749573712955729; MAE for f5: 0.00010411299434883103;\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# With bigger batch_size training is more stable (almost no overfitting) but it does not improve performance\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# N = 10; hidden = 32; batch=32; no significant difference, much longer training; even worse performance\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# N = 10; hidden = 32; batch=32; mlp - 3 layers for encoder and decoder each - totally failed to learn sufficient representation; loss after 100 epochs is 2x bigger\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# With gradient clip=100; h=32; b=32; n=5 -> loss plot is more smooth; no performance improvement\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# Using learning constants advised by authors of graphcast does not improve performance (it is actually worse) but training is super stable - no overfittin at all:\n",
    "# clip=32; self.optimizer = torch.optim.AdamW(self.model.parameters(), betas=(0.9, 0.95), weight_decay=0.1); h=32; b=32\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# N = 5; hidden = 32; batch = 4; s = 7\n",
    "\n",
    "# Epoch 100/100, Train Loss: 1848.7699, lr: 3.125e-05 Val Loss: 2230.6389\n",
    "# 735.7001855373383 [s]22666046945865614\n",
    "\n",
    "# RMSE for t2m: 1.8891855143316563; MAE for t2m: 1.4600152796625336;\n",
    "\n",
    "# RMSE for sp: 2.0393454691406316; MAE for sp: 1.5120049358744065;\n",
    "\n",
    "# RMSE for tcc: 0.2860184447921189; MAE for tcc: 0.22666046945865614;\n",
    "\n",
    "# RMSE for u10: 1.4378177755816777; MAE for u10: 1.0736904505733116;\n",
    "\n",
    "# RMSE for v10: 1.4574477223923084; MAE for v10: 1.0663613129750227;\n",
    "\n",
    "# RMSE for tp: 0.0002711004547077864; MAE for tp: 0.00010284140930705948;\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# N = 5; hidden = 32; batch = 4; s = 3\n",
    "\n",
    "# Epoch 99/100, Train Loss: 1955.0575, lr: 0.0005 Val Loss: 2207.3025\n",
    "\n",
    "# 693.315672159195 [s]\n",
    "\n",
    "# RMSE for t2m: 2.3858469221825898; MAE for t2m: 1.8332994478389537;\n",
    "\n",
    "# RMSE for sp: 1.9815898823743083; MAE for sp: 1.4750331930477616;\n",
    "\n",
    "# RMSE for tcc: 0.28416700897460695; MAE for tcc: 0.23001444125440887;\n",
    "\n",
    "# RMSE for u10: 1.4444404739897925; MAE for u10: 1.0740849332227052;\n",
    "\n",
    "# RMSE for v10: 1.4384182183045433; MAE for v10: 1.05619047567965;\n",
    "\n",
    "# RMSE for tp: 0.0002669724249068656; MAE for tp: 0.00010341137409668945;\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# N = 5; hidden = 32; batch = 4; s = 5\n",
    "\n",
    "# Epoch 100/100, Train Loss: 1901.1544, lr: 6.25e-05 Val Loss: 2181.1193\n",
    "\n",
    "# 678.085875749588 [s]\n",
    "\n",
    "# RMSE for t2m: 1.8778959983044772; MAE for t2m: 1.4465936457254398;\n",
    "\n",
    "# RMSE for sp: 2.190103341129505; MAE for sp: 1.6404208756272267;\n",
    "\n",
    "# RMSE for tcc: 0.2848521568307657; MAE for tcc: 0.22361195825242483;\n",
    "\n",
    "# RMSE for u10: 1.437490006965024; MAE for u10: 1.0706755302203412;\n",
    "\n",
    "# RMSE for v10: 1.4364091328286357; MAE for v10: 1.0579831289563082;\n",
    "\n",
    "# RMSE for tp: 0.0002660477946055829; MAE for tp: 0.00010596483422627151;\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# N = 5; hidden = 32; batch = 4; s = 5; r=2\n",
    "\n",
    "# Epoch 100/100, Train Loss: 1882.7291, lr: 1.5625e-05 Val Loss: 2143.8953 (*at some point 2129)\n",
    "\n",
    "# 887.3842961788177 [s]\n",
    "\n",
    "# RMSE for t2m: 1.8323451416138599; MAE for t2m: 1.4136113810162858;\n",
    "\n",
    "# RMSE for sp: 2.0521229454022802; MAE for sp: 1.527130837420577;\n",
    "\n",
    "# RMSE for tcc: 0.2793271584790608; MAE for tcc: 0.21826436014217337;\n",
    "\n",
    "# RMSE for u10: 1.3972067698487758; MAE for u10: 1.0433846660489516;\n",
    "\n",
    "# RMSE for v10: 1.4072224335796066; MAE for v10: 1.0366618030650943;\n",
    "\n",
    "# RMSE for tp: 0.00026956517312684114; MAE for tp: 0.0001043501217544922;\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# N = 5; hidden = 32; batch = 4; s = 5; r = 2; 32x48;\n",
    "\n",
    "# Epoch 100/100, Train Loss: 2461.7144, lr: 6.25e-05 Val Loss: 3011.8880\n",
    "\n",
    "# 1520.1190974712372 [s]\n",
    "\n",
    "# RMSE for t2m: 1.7308520625058639; MAE for t2m: 1.3247728998925457;\n",
    "\n",
    "# RMSE for sp: 2.3992479669737645; MAE for sp: 1.7568102339318754;\n",
    "\n",
    "# RMSE for tcc: 0.2805274129657387; MAE for tcc: 0.21913696437798416;\n",
    "\n",
    "# RMSE for u10: 1.4401554352858472; MAE for u10: 1.0654466357169252;\n",
    "\n",
    "# RMSE for v10: 1.4595404951536077; MAE for v10: 1.0686582104736524;\n",
    "\n",
    "# RMSE for tp: 0.0002717262792747912; MAE for tp: 0.00010331567566263692;\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# N = 5; hidden = 32; batch = 4; s = 5; r = 2; 32x48 -> 25x45;\n",
    "# ~ 1140 s; Train Loss: 1686.4399, lr: 6.25e-05Val Loss: 2182.0108 (2 trainings)\n",
    "\n",
    "# RMSE for t2m: 1.784685209006511; MAE for t2m: 1.3758342778804562;\n",
    "\n",
    "# RMSE for sp: 2.7761703742751234; MAE for sp: 2.0798808012966767;\n",
    "\n",
    "# RMSE for tcc: 0.278589605641175; MAE for tcc: 0.21694147138915904;\n",
    "\n",
    "# RMSE for u10: 1.413366736459174; MAE for u10: 1.0589858767124307;\n",
    "\n",
    "# RMSE for v10: 1.416900322369188; MAE for v10: 1.0449888444043014;\n",
    "\n",
    "# RMSE for tp: 0.00027346005336134616; MAE for tp: 0.00010490509133304818;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
